{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA1IFM6g1iWp",
        "outputId": "b2f0886f-390a-44cc-f17a-5aaeb4a553a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "9NP4vf3G15IC",
        "outputId": "2b5eb438-e167-48cb-8106-fd4de3ae1856"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcdf8f22770>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(x_train[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "BzTpWHDu152M",
        "outputId": "f59aae9c-6ec3-4028-87f0-d5acf5a3de63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcdf59f70a0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(x_train[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wd5Gr87y18IU"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFyq9MST1_B5",
        "outputId": "0805e278-d981-4664-e9f4-be9c16f98b43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape\n",
        "(60000, 28, 28)\n",
        "x_test.shape\n",
        "(10000, 28, 28, 1)\n",
        "y_train.shape\n",
        "(60000,)\n",
        "y_test.shape\n",
        "(10000,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI80z_lb2CxH",
        "outputId": "1645b263-0611-4ab6-95ed-87b2c3ab957b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               147584    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 241546 (943.54 KB)\n",
            "Trainable params: 241546 (943.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "keras.layers.MaxPooling2D((2,2)),\n",
        "keras.layers.Dropout(0.25),\n",
        "keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "keras.layers.MaxPooling2D((2,2)),\n",
        "keras.layers.Dropout(0.25),\n",
        "keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "keras.layers.Flatten(),\n",
        "keras.layers.Dense(128, activation='relu'),\n",
        "keras.layers.Dropout(0.25),\n",
        "keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYaiqb5-24rn",
        "outputId": "47dc4984-69d0-4eea-f708-6e593497cbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.5647 - accuracy: 0.7910 - val_loss: 0.3750 - val_accuracy: 0.8623\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 71s 38ms/step - loss: 0.3691 - accuracy: 0.8646 - val_loss: 0.3275 - val_accuracy: 0.8813\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 74s 39ms/step - loss: 0.3239 - accuracy: 0.8809 - val_loss: 0.2978 - val_accuracy: 0.8898\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.2956 - accuracy: 0.8900 - val_loss: 0.2798 - val_accuracy: 0.8964\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 71s 38ms/step - loss: 0.2792 - accuracy: 0.8958 - val_loss: 0.2683 - val_accuracy: 0.9013\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.2667 - accuracy: 0.9010 - val_loss: 0.2651 - val_accuracy: 0.9000\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 72s 39ms/step - loss: 0.2528 - accuracy: 0.9065 - val_loss: 0.2596 - val_accuracy: 0.9061\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.2471 - accuracy: 0.9073 - val_loss: 0.2579 - val_accuracy: 0.9053\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.2364 - accuracy: 0.9096 - val_loss: 0.2545 - val_accuracy: 0.9091\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 72s 39ms/step - loss: 0.2282 - accuracy: 0.9150 - val_loss: 0.2539 - val_accuracy: 0.9100\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9iZJl6025VH",
        "outputId": "f55f3fc9-f37a-4b58-fb3f-1d479d114856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2539 - accuracy: 0.9100\n",
            "Test accuracy: 91.00000262260437\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This code snippet demonstrates building a Convolutional Neural Network (CNN) using TensorFlow/Keras for classifying fashion items from the Fashion MNIST dataset. Let's go through each part of the code:\n",
        "\n",
        "# Libraries Imported\n",
        "# import tensorflow as tf: TensorFlow library for deep learning.\n",
        "# import matplotlib.pyplot as plt: Matplotlib for plotting.\n",
        "# from tensorflow import keras: Keras for building and training neural networks.\n",
        "# import numpy as np: NumPy for numerical operations.\n",
        "# Loading and Preprocessing Data\n",
        "# keras.datasets.fashion_mnist.load_data(): Loads the Fashion MNIST dataset, consisting of images of clothing items and their corresponding labels.\n",
        "# The training and test images are normalized to values between 0 and 1 by dividing by 255.0.\n",
        "# Reshapes the images to have a single channel (grayscale) and a shape of (28, 28, 1).\n",
        "# Model Definition\n",
        "# keras.Sequential([...]): Initializes a sequential model.\n",
        "# Adds three convolutional layers (Conv2D) with ReLU activation and max-pooling layers (MaxPooling2D).\n",
        "# Dropout layers are added after each max-pooling layer for regularization.\n",
        "# A flatten layer converts the 2D feature map to a 1D vector.\n",
        "# Two dense layers (Dense) with ReLU activation and softmax activation for the output layer (classification).\n",
        "# Model Compilation and Training\n",
        "# model.compile(...): Compiles the model with the Adam optimizer, sparse categorical cross-entropy loss, and accuracy metric.\n",
        "# model.fit(...): Trains the model on the training data for 10 epochs with validation data for evaluation during training.\n",
        "# Model Evaluation\n",
        "# model.evaluate(...): Evaluates the trained model on the test data and computes the test loss and accuracy.\n",
        "# Prints the test accuracy after evaluation.\n",
        "# Summary\n",
        "# The model architecture includes three convolutional layers followed by max-pooling and dropout for regularization, then dense layers for classification.\n",
        "# The Adam optimizer is used with sparse categorical cross-entropy loss for multiclass classification.\n",
        "# The model is trained for 10 epochs on the Fashion MNIST dataset, achieving a test accuracy printed at the end.\n",
        "# Overall, this code showcases building and training a CNN using TensorFlow/Keras for image classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Group B Deep Learning\n",
        "#  Assignment No: 3B\n",
        "#  Title of the Assignment: Use MNIST Fashion Dataset and create a classifier to classify fashion clothing\n",
        "#  into categories.\n",
        "#  Objective of the Assignment: Students should be able to Classify movie reviews into positive reviews\n",
        "#  and \"negative reviews on IMDB Dataset.\n",
        "#  Prerequisite:\n",
        "#  1.\n",
        "#  2.\n",
        "#  3.\n",
        "#  Basic of programming language\n",
        "#  Concept of Classification\n",
        "#  Concept of Deep Neural Network--------------------------------------------------------------------------------------------------------------\n",
        "# Contents for Theory:\n",
        "#  1.\n",
        "#  2.\n",
        "#  3.\n",
        "#  4.\n",
        "#  5.\n",
        "#  What is Classification\n",
        "#  Example of Classification\n",
        "#  What is CNN?\n",
        "#  How Deep Neural Network Work on Classification\n",
        "#  Code Explanation with Output--------------------------------------------------------------------------------------------------------------\n",
        "# SNJB’s Late Sau. K.B. Jain College Of Engineering\n",
        "# What is Classification?\n",
        "#  Classification is a type of supervised learning in machine learning that involves categorizing data into\n",
        "#  predefined classes or categories based on a set of features or characteristics. It is used to predict the class\n",
        "#  of new, unseen data based on the patterns learned from the labeled training data.\n",
        "#  In classification, a model is trained on a labeled dataset, where each data point has a known class label.\n",
        "#  The model learns to associate the input features with the corresponding class labels and can then be used\n",
        "#  to classify new, unseen data.\n",
        "#  For example, we can use classification to identify whether an email is spam or not based on its content\n",
        "#  and metadata, to predict whether a patient has a disease based on their medical records and symptoms, or\n",
        "#  to classify images into different categories based on their visual features.\n",
        "#  Classification algorithms can vary in complexity, ranging from simple models such as decision trees and\n",
        "#  k-nearest neighbors to more complex models such as support vector machines and neural networks. The\n",
        "#  choice of algorithm depends on the nature of the data, the size of the dataset, and the desired level of\n",
        "#  accuracy and interpretability.\n",
        "#  Example- Classification is a common task in deep neural networks, where the goal is to predict the class\n",
        "#  of an input based on its features. Here's an example of how classification can be performed in a deep\n",
        "#  neural network using the popular MNIST dataset of handwritten digits.\n",
        "#  The MNIST dataset contains 60,000 training images and 10,000 testing images of handwritten digits\n",
        "#  from 0 to 9. Each image is a grayscale 28x28 pixel image, and the task is to classify each image into one\n",
        "#  of the 10 classes corresponding to the 10 digits.\n",
        "#  We can use a convolutional neural network (CNN) to classify the MNIST dataset. A CNN is a type of\n",
        "#  deep neural network that is commonly used for image classification tasks.\n",
        "#  What us CNN\n",
        "# Convolutional Neural Networks (CNNs) are commonly used for image classification tasks, and they are\n",
        "#  designed to automatically learn and extract features from input images. Let's consider an example of\n",
        "#  using a CNN to classify images of handwritten digits.\n",
        "#  SNJB’s Late Sau. K.B. Jain College Of Engineering\n",
        "# In a typical CNN architecture for image classification, there are several layers, including convolutional\n",
        "#  layers, pooling layers, and fully connected layers. Here's a diagram of a simple CNN architecture for the\n",
        "#  digit classification task:\n",
        "#  The input to the network is an image of size 28x28 pixels, and the output is a probability distribution\n",
        "#  over the 10 possible digits (0 to 9).\n",
        "#  The convolutional layers in the CNN apply filters to the input image, looking for specific patterns and\n",
        "#  features. Each filter produces a feature map that highlights areas of the image that match the filter. The\n",
        "#  filters are learned during training, so the network can automatically learn which features are most\n",
        "#  relevant for the classification task.\n",
        "#  The pooling layers in the CNN downsample the feature maps, reducing the spatial dimensions of the\n",
        "#  data. This helps to reduce the number of parameters in the network, while also making the features more\n",
        "#  robust to small variations in the input image.\n",
        "#  The fully connected layers in the CNN take the flattened output from the last pooling layer and perform\n",
        "#  a classification task by outputting a probability distribution over the 10 possible digits.\n",
        "#  During training, the network learns the optimal values of the filters and parameters by minimizing a loss\n",
        "#  function. This is typically done using stochastic gradient descent or a similar optimization algorithm.\n",
        "#  Once trained, the network can be used to classify new images by passing them through the network and\n",
        "#  computing the output probability distribution.\n",
        "#  Overall, CNNs are powerful tools for image recognition tasks and have been used successfully in many\n",
        "#  applications, including object detection, face recognition, and medical image analysis.\n",
        "#  CNNs have a wide range of applications in various fields, some of which are:\n",
        "#  Image classification: CNNs are commonly used for image classification tasks, such as identifying\n",
        "#  objects in images and recognizing faces.\n",
        "#  Object detection: CNNs can be used for object detection in images and videos, which involves\n",
        "#  identifying the location of objects in an image and drawing bounding boxes around them.\n",
        "#  Semantic segmentation: CNNs can be used for semantic segmentation, which involves partitioning an\n",
        "#  image into segments and assigning each segment a semantic label (e.g., \"road\", \"sky\", \"building\").\n",
        "#  Natural language processing: CNNs can be used for natural language processing tasks, such as\n",
        "#  sentiment analysis and text classification.\n",
        "#  Medical imaging: CNNs are used in medical imaging for tasks such as diagnosing diseases from X-rays\n",
        "#  and identifying tumors from MRI scans.\n",
        "#  Autonomous vehicles: CNNs are used in autonomous vehicles for tasks such as object detection and\n",
        "#  lane detection.\n",
        "#  SNJB’s Late Sau. K.B. Jain College Of Engineering\n",
        "# Video analysis: CNNs can be used for tasks such as video classification, action recognition, and video\n",
        "#  captioning.\n",
        "#  Overall, CNNs are a powerful tool for a wide range of applications, and they have been used\n",
        "#  successfully in many areas of research and industry.\n",
        "#  How Deep Neural Network Work on Classification using CNN\n",
        "# Deep neural networks using CNNs work on classification tasks by learning to automatically extract\n",
        "#  features from input images and using those features to make predictions. Here's how it works:\n",
        "#  Input layer: The input layer of the network takes in the image data as input.\n",
        "#  Convolutional layers: The convolutional layers apply filters to the input images to extract relevant\n",
        "#  features. Each filter produces a feature map that highlights areas of the image that match the filter.\n",
        "#  Activation functions: An activation function is applied to the output of each convolutional layer to\n",
        "#  introduce non-linearity into the network.\n",
        "#  Pooling layers: The pooling layers downsample the feature maps to reduce the spatial dimensions of the\n",
        "#  data.\n",
        "#  Dropout layer: Dropout is used to prevent overfitting by randomly dropping out a percentage of the\n",
        "#  neurons in the network during training.\n",
        "#  Fully connected layers: The fully connected layers take the flattened output from the last pooling layer\n",
        "#  and perform a classification task by outputting a probability distribution over the possible classes.\n",
        "#  Softmax activation function: The softmax activation function is applied to the output of the last fully\n",
        "#  connected layer to produce a probability distribution over the possible classes.\n",
        "#  Loss function: A loss function is used to compute the difference between the predicted probabilities and\n",
        "#  the actual labels.\n",
        "#  Optimization: An optimization algorithm, such as stochastic gradient descent, is used to minimize the\n",
        "#  loss function by adjusting the values of the network parameters.\n",
        "#  Training: The network is trained on a large dataset of labeled images, adjusting the values of the\n",
        "#  parameters to minimize the loss function.\n",
        "#  Prediction: Once trained, the network can be used to classify new images by passing them through the\n",
        "#  network and computing the output probability distribution.\n",
        "#  MNIST Dataset\n",
        "# The MNIST Fashion dataset is a collection of 70,000 grayscale images of 28x28 pixels, representing 10\n",
        "#  different categories of clothing and accessories. The categories include T-shirts/tops, trousers, pullovers,\n",
        "#  dresses, coats, sandals, shirts, sneakers, bags, and ankle boots.\n",
        "#  The dataset is often used as a benchmark for testing image classification algorithms, and it is considered\n",
        "#  a more challenging version of the original MNIST dataset which contains handwritten digits. The\n",
        "#  SNJB’s Late Sau. K.B. Jain College Of Engineering\n",
        "# MNIST Fashion dataset was released by Zalando Research in 2017 and has since become a popular\n",
        "#  dataset in the machine learning community.\n",
        "#  he MNIST Fashion dataset is a collection of 70,000 grayscale images of 28x28 pixels each. These\n",
        "#  images represent 10 different categories of clothing and accessories, with each category containing 7,000\n",
        "#  images. The categories are as follows:\n",
        "#  T-shirt/tops\n",
        "#  Trousers\n",
        "#  Pullovers\n",
        "#  Dresses\n",
        "#  Coats\n",
        "#  Sandals\n",
        "#  Shirts\n",
        "#  Sneakers\n",
        "#  Bags\n",
        "#  Ankle boots\n",
        "#  The images were obtained from Zalando's online store and are preprocessed to be normalized and\n",
        "#  centered. The training set contains 60,000 images, while the test set contains 10,000 images. The goal of\n",
        "#  the dataset is to accurately classify the images into their respective categories.\n",
        "#  The MNIST Fashion dataset is often used as a benchmark for testing image classification algorithms,\n",
        "#  and it is considered a more challenging version of the original MNIST dataset which contains\n",
        "#  handwritten digits. The dataset is widely used in the machine learning community for research and\n",
        "#  educational purposes.\n",
        "#  SNJB’s Late Sau. K.B. Jain College Of Engineering\n",
        "# Hereare thegeneral steps toperformConvolutionalNeuralNetwork(CNN)ontheMNISTFashion\n",
        "#  dataset:\n",
        "#  ● Import the necessary libraries, including TensorFlow, Keras, NumPy, and Matplotlib.\n",
        "#  ● Load thedataset usingKeras' built-in function, keras.datasets.fashion_mnist.load_data(). This\n",
        "#  will provide the training and testing sets, which will be used to train and evaluate the CNN.\n",
        "#  ● Preprocessthedatabynormalizingthepixelvaluesbetween0and1,andreshapingtheimagesto\n",
        "#  be of size (28, 28, 1) for compatibility with the CNN.\n",
        "#  ● Define theCNNarchitecture, includingthenumberandsizeoffilters,activationfunctions,and\n",
        "#  pooling layers. This can vary based on the specific problem being addressed.\n",
        "#  ● Compilethemodelbyspecifyingthelossfunction,optimizer,andevaluationmetrics.Common\n",
        "#  choices include categorical cross-entropy, Adam optimizer, and accuracy metric.\n",
        "#  ● TraintheCNNonthetrainingsetusingthefit()function,specifyingthenumberofepochsand\n",
        "#  batch size.\n",
        "#  ● Evaluatetheperformanceof themodelonthetestingsetusingtheevaluate()function.Thiswill\n",
        "#  provide metrics such as accuracy and loss on the test set.\n",
        "#  ● Use the trainedmodel tomake predictions onnew images, if desired, using the predict()\n",
        "#  function.\n",
        "#  Source Code with Output\n",
        "# importtensorflowastf\n",
        "#  importmatplotlib.pyplotasplt\n",
        "#  fromtensorflowimportkeras\n",
        "#  importnumpyasnp\n",
        "#  (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "#  #Thereare10imageclassesinthisdatasetandeachclasshasamappingcorrespondingtothefollowing\n",
        "#  labels:\n",
        "#  #0 T-shirt/top\n",
        "#  #1 Trouser\n",
        "#  #2 pullover\n",
        "#  #3 Dress\n",
        "#  #4 Coat\n",
        "#  #5 sandals\n",
        "#  SNJB’s Late Sau. K.B. Jain College Of Engineering\n",
        "# #6 shirt\n",
        "#  #7 sneaker\n",
        "#  #8 bag\n",
        "#  #9 ankle boot\n",
        "#  plt.imshow(x_train[1])\n",
        "#  plt.imshow(x_train[0])\n",
        "#  # Next, we will preprocess the data by scaling the pixel values to be between 0 and 1, and then reshaping\n",
        "#  the images to be 28x28 pixels.\n",
        "#  x_train = x_train.astype('float32') / 255.0\n",
        "#  x_test = x_test.astype('float32') / 255.0\n",
        "#  x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "#  x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "#  # 28, 28 comes from width, height, 1 comes from the number of channels\n",
        "#  # -1 means that the length in that dimension is inferred.\n",
        "#  # This is done based on the constraint that the number of elements in an ndarray or Tensor when\n",
        "#  reshaped must remain the same.\n",
        "#  SNJB’s Late Sau. K.B. Jain College Of Engineering\n",
        "# #eachimageisarowvector(784elements)andtherearelotsofsuchrows(letitben,sothereare784n\n",
        "#  elements). So TensorFlow can infer that -1 is n.\n",
        "#  #convertingthetraining_imagesarrayto4dimensionalarraywithsizes60000,28,28,1for0thto3rd\n",
        "#  dimension.\n",
        "#  x_train.shape\n",
        "#  (60000, 28, 28)\n",
        "#  x_test.shape\n",
        "#  (10000, 28, 28, 1)\n",
        "#  y_train.shape\n",
        "#  (60000,)\n",
        "#  y_test.shape\n",
        "#  (10000,)\n",
        "#  # We will use a convolutional neural network (CNN) to classify the fashion items.\n",
        "#  # The CNN will consist of multiple convolutional layers followed by max pooling,\n",
        "#  # dropout, and dense layers. Here is the code for the model:\n",
        "#  model = keras.Sequential([\n",
        "#  keras.layers.Conv2D(32, (3,3), activation='relu',input_shape=(28,28,1)),\n",
        "#  # 32 filters (default), randomly initialized\n",
        "#  # 3*3 is Size of Filter\n",
        "#  # 28,28,1 size of Input Image\n",
        "#  # No zero-padding: every output 2 pixels lessin every dimension\n",
        "#  # in Paramter shwon 320 is value of weights: (3x3filter weights + 32 bias) * 32 filters\n",
        "#  # 32*3*3=288(Total)+32(bias)= 320\n",
        "#  keras.layers.MaxPooling2D((2,2)),\n",
        "#  # It shown 13 * 13 size image with 32 channelor filter or depth.\n",
        "#  keras.layers.Dropout(0.25),\n",
        "#  # Reduce Overfitting of Training sample drop out25% Neuron\n",
        "#  keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "#  # Deeper layers use 64 filters\n",
        "#  # 3*3 is Size of Filter\n",
        "#  # Observe how the input image on 28x28x1 is transformedto a 3x3x64 feature map\n",
        "#  # 13(Size)-3(Filter Size )+1(bias)=11 Size forWidth and Height with 64 Depth or filtter or channel\n",
        "#  # in Paramter shwon 18496 is value of weights:(3x3 filter weights + 64 bias) * 64 filters\n",
        "#  # 64*3*3=576+1=577*32 + 32(bias)=18496\n",
        "#  keras.layers.MaxPooling2D((2,2)),\n",
        "#  # It shown 5 * 5 size image with 64 channel orfilter or depth.\n",
        "#  keras.layers.Dropout(0.25),\n",
        "#  SNJB’s Late Sau. K.B. Jain College Of Engineering\n",
        "# keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "#  # Deeper layers use 128 filters\n",
        "#  # 3*3 is Size of Filter\n",
        "#  # Observe how the input image on 28x28x1 is transformedto a 3x3x128 feature map\n",
        "#  #It show5(Size)-3(FilterSize)+1(bias)=3SizeforWidthandHeightwith64Depthor filtteror\n",
        "#  channel\n",
        "#  # 128*3*3=1152+1=1153*64 + 64(bias)= 73856\n",
        "#  # To classify the images, we still need a Denseand Softmax layer.\n",
        "#  # We need to flatten the 3x3x128 feature map toa vector of size 1152\n",
        "#  keras.layers.Flatten(),\n",
        "#  keras.layers.Dense(128, activation='relu'),\n",
        "#  # 128 Size of Node in Dense Layer\n",
        "#  # 1152*128 = 147584\n",
        "#  keras.layers.Dropout(0.25),\n",
        "#  keras.layers.Dense(10, activation='softmax')\n",
        "#  # 10 Size of Node another Dense Layer\n",
        "#  # 128*10+10 bias= 1290\n",
        "#  ])\n",
        "#  model.summary()\n",
        "#  Model: \"sequential\"\n",
        "#  _________________________________________________________________\n",
        "#  Layer (type)                Output Shape              Param #\n",
        "#  =================================================================\n",
        "#  conv2d (Conv2D)             (None, 26, 26, 32)        320\n",
        "#  max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0\n",
        "#  )\n",
        "#  dropout (Dropout)           (None, 13, 13, 32)        0\n",
        "#  conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496\n",
        "#  max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0\n",
        "#  2D)\n",
        "#  dropout_1 (Dropout)         (None, 5, 5, 64)          0\n",
        "#  SNJB’s Late Sau. K.B. Jain College Of Engineering\n",
        "# conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856\n",
        "#  flatten (Flatten)           (None, 1152)              0\n",
        "#  dense (Dense)               (None, 128)               147584\n",
        "#  dropout_2 (Dropout)         (None, 128)               0\n",
        "#  dense_1 (Dense)             (None, 10)                1290\n",
        "#  =================================================================\n",
        "#  Total params: 241,546\n",
        "#  Trainable params: 241,546\n",
        "#  Non-trainable params: 0\n",
        "#  # Compile and Train the Model\n",
        "#  # After defining the model, we will compile it and train it on the training data.\n",
        "#  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "#  history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))\n",
        "#  # 1875 is a number of batches. By default batches contain 32 samles.60000 / 32 = 1875\n",
        "#  # Finally, we will evaluate the performance of the model on the test data.\n",
        "#  test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "#  print('Test accuracy:', test_acc)\n",
        "#  313/313 [==============================] - 3s 10ms/step - loss: 0.2606 - accuracy: 0.9031\n",
        "#  Test accuracy: 0.9031000137329102\n",
        "#  Conclusion- In this way we can Classify fashion clothinginto categories using CNN.\n",
        "#  Assignment Question\n",
        "#  1. What is Binary Classification?\n",
        "#  2. What is binary Cross Entropy?\n",
        "#  3. What is Validation Split?\n",
        "#  4. What  is the Epoch Cycle?\n",
        "#  5. What is Adam Optimizer?\n",
        "#  SNJB’s Late Sau. K.B. Jain College Of Engineerin"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
